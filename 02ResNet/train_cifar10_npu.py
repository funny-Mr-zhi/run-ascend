# å¿½ç•¥éå…³é”®è­¦å‘Š
import warnings
warnings.filterwarnings('ignore', category=UserWarning)

import os
import time
import argparse
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import torchvision.models as models

# === NPU æ ¸å¿ƒç»„ä»¶å¯¼å…¥ ===
import torch_npu
from torch_npu.npu import amp
from torch_npu.optim import NpuFusedSGD # ä½¿ç”¨æ˜‡è…¾ä¸“ç”¨èåˆä¼˜åŒ–å™¨

def main():
    parser = argparse.ArgumentParser(description='PyTorch CIFAR-10 Training on Ascend 910B')
    parser.add_argument('--data', default='../../dataset/', help='æ•°æ®é›†å­˜æ”¾è·¯å¾„ (ä¼šè‡ªåŠ¨ä¸‹è½½)')
    parser.add_argument('--epochs', default=50, type=int, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch-size', default=128, type=int, help='Batch Size')
    parser.add_argument('--num-workers', default=4, type=int, help='æ•°æ®åŠ è½½çº¿ç¨‹æ•°')
    parser.add_argument('--lr', default=0.1, type=float, help='åˆå§‹å­¦ä¹ ç‡')
    parser.add_argument('--device-id', default=0, type=int, help='NPUè®¾å¤‡ID')
    args = parser.parse_args()

    # 1. ç¯å¢ƒåˆå§‹åŒ–
    device = torch.device(f"npu:{args.device_id}")
    torch.npu.set_device(device)
    print(f"ğŸš€ Running on Ascend 910B (Device: {device})")

    # 2. æ•°æ®å‡†å¤‡ (CIFAR-10)
    print("â³ Preparing Data...")
    
    # CIFAR-10 çš„æ ‡å‡†æ•°æ®å¢å¼º
    transform_train = transforms.Compose([
        transforms.RandomCrop(32, padding=4),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
    ])

    transform_test = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
    ])

    # ä¸‹è½½å¹¶åŠ è½½æ•°æ®é›† (num_workers æ ¹æ® CPU æ ¸æ•°è°ƒæ•´ï¼Œå»ºè®® 4-8)
    trainset = torchvision.datasets.CIFAR10(
        root=args.data, train=True, download=True, transform=transform_train)
    train_loader = torch.utils.data.DataLoader(
        trainset, batch_size=args.batch_size, shuffle=True, 
        num_workers=args.num_workers, pin_memory=True, drop_last=True) # pin_memory=True åŠ é€Ÿ host åˆ° device ä¼ è¾“

    testset = torchvision.datasets.CIFAR10(
        root=args.data, train=False, download=True, transform=transform_test)
    test_loader = torch.utils.data.DataLoader(
        testset, batch_size=args.batch_size, shuffle=False, 
        num_workers=args.num_workers, pin_memory=True)

    # 3. æ¨¡å‹å®šä¹‰ (é­”æ”¹ç‰ˆ ResNet50)
    print("ğŸ§  Building Model...")
    # num_classes=10 å¯¹åº” CIFAR-10 çš„ç±»åˆ«æ•°
    model = models.resnet50(num_classes=10)
    
    # === å…³é”®ä¿®æ”¹ ===
    # æ ‡å‡† ResNet50 ç¬¬ä¸€å±‚æ˜¯ 7x7 å·ç§¯ + 2å€ä¸‹é‡‡æ ·ï¼Œé€‚åˆ 224x224 å¤§å›¾ã€‚
    # å¯¹äº CIFAR-10 (32x32)ï¼Œæˆ‘ä»¬éœ€è¦æŠŠç¬¬ä¸€å±‚æ”¹æˆ 3x3 å·ç§¯ï¼Œå»æ‰ strideï¼Œ
    # å¦åˆ™ç‰¹å¾å›¾åœ¨è¿›å…¥ç½‘ç»œæ·±å±‚å‰å°±å˜å¾—å¤ªå°äº†ï¼Œå¯¼è‡´ç²¾åº¦æ— æ³•æå‡ã€‚
    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
    model.maxpool = nn.Identity() # å»æ‰ç¬¬ä¸€å±‚çš„ MaxPool
    
    model = model.to(device)

    # 4. ä¼˜åŒ–å™¨ä¸ Loss
    criterion = nn.CrossEntropyLoss().to(device)
    # ä½¿ç”¨ NPU ä¸“ç”¨èåˆ SGDï¼Œæ¯”åŸç”Ÿ SGD å¿«
    optimizer = NpuFusedSGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)
    # å­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)
    
    # æ··åˆç²¾åº¦ Scaler
    scaler = amp.GradScaler()

    # 5. è®­ç»ƒä¸æµ‹è¯•å¾ªç¯
    best_acc = 0.0
    
    for epoch in range(args.epochs):
        start_time = time.time()
        
        # --- è®­ç»ƒé˜¶æ®µ ---
        train_loss, train_acc, fps = train_one_epoch(
            train_loader, model, criterion, optimizer, scaler, device)
        
        # --- æµ‹è¯•é˜¶æ®µ ---
        val_acc = validate(test_loader, model, device)
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        epoch_time = time.time() - start_time
        
        # æ‰“å°æ—¥å¿—
        print(f"Epoch [{epoch+1}/{args.epochs}] | "
              f"Time: {epoch_time:.1f}s | FPS: {fps:.1f} | "
              f"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | "
              f"Val Acc: {val_acc:.2f}%")

        # --- ä¿å­˜æœ€ä½³æ¨¡å‹ ---
        if val_acc > best_acc:
            best_acc = val_acc
            print(f"ğŸ‰ New Best Accuracy: {best_acc:.2f}%! Saving checkpoint...")
            state = {
                'net': model.state_dict(),
                'acc': val_acc,
                'epoch': epoch,
            }
            if not os.path.isdir('checkpoint'):
                os.mkdir('checkpoint')
            torch.save(state, './checkpoint/ckpt_best.pth')

    print(f"\nâœ… Training Finished. Best Accuracy: {best_acc:.2f}%")

def train_one_epoch(train_loader, model, criterion, optimizer, scaler, device):
    model.train()
    train_loss = 0
    correct = 0
    total = 0
    total_samples = 0
    start_time = time.time()

    for batch_idx, (inputs, targets) in enumerate(train_loader):
        # å¼‚æ­¥ä¼ è¾“æ•°æ®åˆ° NPU
        inputs = inputs.to(device, non_blocking=True)
        targets = targets.to(device, non_blocking=True)

        # æ··åˆç²¾åº¦å‰å‘è®¡ç®— (FP16)
        with amp.autocast():
            outputs = model(inputs)
            loss = criterion(outputs, targets)

        # åå‘ä¼ æ’­ä¸ä¼˜åŒ–
        optimizer.zero_grad()
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        # ç»Ÿè®¡æ•°æ®
        train_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()
        total_samples += targets.size(0)

    end_time = time.time()
    fps = total_samples / (end_time - start_time)
    
    return train_loss / (batch_idx + 1), 100. * correct / total, fps

def validate(test_loader, model, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for inputs, targets in test_loader:
            inputs = inputs.to(device, non_blocking=True)
            targets = targets.to(device, non_blocking=True)
            
            # æ¨ç†æ—¶ä¹Ÿå¯ä»¥å¼€å¯æ··åˆç²¾åº¦åŠ é€Ÿ
            with amp.autocast():
                outputs = model(inputs)
                
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()

    return 100. * correct / total

if __name__ == '__main__':
    main()