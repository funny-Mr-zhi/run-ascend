import time
import torch
import torch.nn.functional as F
from torch_geometric.datasets import Planetoid
from torch_geometric.nn import GCNConv
import torch_geometric.transforms as T

import warnings
warnings.filterwarnings('ignore', category=UserWarning)

# === NPU æ ¸å¿ƒç»„ä»¶ ===
import torch_npu
from torch_npu.optim import NpuFusedAdam  # GNN è¿™é‡Œçš„ç¥å™¨

# å±è”½è­¦å‘Š
import warnings
warnings.filterwarnings('ignore')

def main():
    # 1. ç¯å¢ƒåˆå§‹åŒ–
    device = torch.device('npu:0')
    torch.npu.set_device(device)
    print(f"ğŸš€ Running GNN on Ascend 910B (Device: {device})")

    # 2. å‡†å¤‡æ•°æ® (Cora)
    print("â³ Loading Cora Dataset...")
    dataset = Planetoid(root='../dataset/Cora', name='Cora', transform=T.NormalizeFeatures())
    data = dataset[0]
    
    # å°†æ•´ä¸ªå›¾æ•°æ®æ¬è¿åˆ° NPU
    # æ³¨æ„ï¼šGNN é€šå¸¸æ˜¯ä¸€æ¬¡æ€§æŠŠæ•´ä¸ªå›¾(x, edge_index)æ”¾åˆ°æ˜¾å­˜é‡Œ
    data = data.to(device)

    # 3. å®šä¹‰ GCN æ¨¡å‹
    class GCN(torch.nn.Module):
        def __init__(self):
            super().__init__()
            # PyG çš„ GCNConv åº•å±‚ä¼šè‡ªåŠ¨è°ƒç”¨ torch.scatter ç­‰ç®—å­
            # åœ¨ NPU ä¸Šä¼šè¢«æ˜ å°„åˆ°é«˜æ€§èƒ½çš„ AICore ç®—å­ä¸Š
            self.conv1 = GCNConv(dataset.num_features, 16)
            self.conv2 = GCNConv(16, dataset.num_classes)

        def forward(self, x, edge_index):
            x = self.conv1(x, edge_index)
            x = F.relu(x)
            x = F.dropout(x, training=self.training)
            x = self.conv2(x, edge_index)
            return F.log_softmax(x, dim=1)

    model = GCN().to(device)
    
    # 4. ä¼˜åŒ–å™¨ (ä½¿ç”¨ NPU èåˆ Adam)
    # GNN å‚æ•°é€šå¸¸æ¯”è¾ƒç¨€ç–ï¼ŒFusedAdam èƒ½æ˜¾è‘—å‡å°‘ CPU ä¸‹å‘æŒ‡ä»¤çš„å¼€é”€
    optimizer = NpuFusedAdam(model.parameters(), lr=0.01, weight_decay=5e-4)

    # 5. è®­ç»ƒå¾ªç¯
    print("ğŸ”¥ Start Training...")
    model.train()
    
    # è®°å½•æ—¶é—´
    times = []
    
    for epoch in range(200):
        start = time.time()
        
        optimizer.zero_grad()
        out = model(data.x, data.edge_index)
        
        # ä»…è®¡ç®—è®­ç»ƒé›†çš„ Loss
        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])
        loss.backward()
        optimizer.step()
        
        torch.npu.synchronize() # å‡†ç¡®è®¡æ—¶éœ€è¦
        end = time.time()
        times.append(end - start)

        if epoch % 20 == 0:
            # ç®€å•éªŒè¯ä¸€ä¸‹ç²¾åº¦
            model.eval()
            pred = model(data.x, data.edge_index).argmax(dim=1)
            correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()
            acc = int(correct) / int(data.test_mask.sum())
            model.train()
            print(f'Epoch {epoch:03d}: Loss: {loss.item():.4f}, Test Acc: {acc:.4f}')

    avg_time = sum(times) / len(times) * 1000 # è½¬ä¸ºæ¯«ç§’
    print(f"\nâœ… Training Finished!")
    print(f"Average Epoch Time: {avg_time:.2f} ms")
    print("If this runs without error, your PyG environment is ready!")

if __name__ == '__main__':
    main()